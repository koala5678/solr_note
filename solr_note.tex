% Created 2017-01-03 二 12:08
% Intended LaTeX compiler: pdflatex
\documentclass[presentation]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme{default}
\author{吴丹阳}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={吴丹阳},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.1.1 (Org mode 9.0.2)}, 
 pdflang={English}}
\begin{document}

\begin{frame}{Outline}
\tableofcontents
\end{frame}

\begin{frame}[fragile,label={sec:org3661264}]{Quick Start}
 \begin{block}{Prerequisite}
\begin{block}{Java Run Environment(JRE)}
\begin{itemize}
\item version >= 1.8
\end{itemize}
\begin{verbatim}
java -version
\end{verbatim}
\end{block}
\end{block}


\begin{block}{Installing Solr}
\begin{verbatim}
wget http://lucene.apache.org/solr/
cd /path/to/solr_arch
tar zxf solr-x.y.z.tgz
\end{verbatim}
\end{block}


\begin{block}{Running Solr}
\begin{verbatim}
bin/solr start
bin/solr -help
# 指定命令的帮助文档
bin/solr start -help

# 前端开启Foreground
bin/solr start -f
# 指定端口 (默认是8983)
bin/solr start -p 8984
bin/solr stop [-p 8983 | -all]

# 启动示例
bin/solr -e techproducts [techproducts, dih, schemaless, and cloud.]

bin/solr status
\end{verbatim}

➜  solr bin/solr -e techproducts
\begin{verbatim}
➜  solr bin/solr -e techproducts
Solr home directory /Users/wudanyang/self/solr/example/techproducts/solr already exists.

Starting up Solr on port 8983 using command:
bin/solr start -p 8983 -s "example/techproducts/solr"

Archiving 1 old GC log files to /Users/wudanyang/self/solr/example/techproducts/solr/../logs/archived
Archiving 1 console log files to /Users/wudanyang/self/solr/example/techproducts/solr/../logs/archived
Rotating solr logs, keeping a max of 9 generations
Waiting up to 180 seconds to see Solr running on port 8983 [\]
Started Solr server on port 8983 (pid=28473). Happy searching!


Copying configuration to new core instance directory:
/Users/wudanyang/self/solr/example/techproducts/solr/techproducts

Creating new core 'techproducts' using command:
http://localhost:8983/solr/admin/cores?action=CREATE&name=techproducts&instanceDir=techproducts

{
  "responseHeader":{
    "status":0,
    "QTime":2036},
  "core":"techproducts"}


Indexing tech product example docs from /Users/wudanyang/self/solr/example/exampledocs
SimplePostTool version 5.0.0
Posting files to [base] url http://localhost:8983/solr/techproducts/update using content-type application/xml...
POSTing file gb18030-example.xml to [base]
POSTing file hd.xml to [base]
POSTing file ipod_other.xml to [base]
POSTing file ipod_video.xml to [base]
POSTing file manufacturers.xml to [base]
POSTing file mem.xml to [base]
POSTing file money.xml to [base]
POSTing file monitor.xml to [base]
POSTing file monitor2.xml to [base]
POSTing file mp500.xml to [base]
POSTing file sd500.xml to [base]
POSTing file solr.xml to [base]
POSTing file utf8-example.xml to [base]
POSTing file vidcard.xml to [base]
14 files indexed.
COMMITting Solr index changes to http://localhost:8983/solr/techproducts/update...
Time spent: 0:00:00.601

Solr techproducts example launched successfully. Direct your Web browser to http://localhost:8983/solr to visit the Solr Admin UI
\end{verbatim}
\end{block}


\begin{block}{Create a Core(Collection if on Cloud)}
\begin{itemize}
\item 上面运行的是示例文件,创建自己Core用来索引和搜索文档
\item Core与Solr的关系跟软件与操作系统关系相似
\item 每个core有自身的配置文件及数据
\end{itemize}
\begin{verbatim}
bin/solr create -c <name>
bin/solr create -help
\end{verbatim}
\begin{verbatim}
➜  solr bin/solr create -help
Usage: solr create [-c name] [-d confdir] [-n configName] [-shards \#] [-replicationFactor \#] [-p port]
  Create a core or collection depending on whether Solr is running in standalone (core) or SolrCloud
  mode (collection). In other words, this action detects which mode Solr is running in, and then takes
  the appropriate action (either create_core or create_collection).
\end{verbatim}
\end{block}


\begin{block}{Add Document}
schema 决定了文档的结构
\begin{verbatim}
➜  solr bin/post -help

Usage: post -c <collection> [OPTIONS] <files|directories|urls|-d ["...",...]>
    or post -help

  collection name defaults to DEFAULT_SOLR_COLLECTION if not specified

OPTIONS
=======
  Solr options:
    -url <base Solr update URL> (overrides[包括] collection, host, and port)
    -host <host> (default: localhost)
    -p or -port <port> (default: 8983)
    -commit yes|no (default: yes)
    -u or -user <user:pass> (sets BasicAuth credentials)

  Web crawl options:
    -recursive <depth> (default: 1)
    -delay <seconds> (default: 10)

  Directory crawl options:
    -delay <seconds> (default: 0)

  stdin/args options:
    -type <content/type> (default: application/xml)

  Other options:
    -filetypes <type>[,<type>,...] (default: xml,json,jsonl,csv,pdf,doc,docx,ppt,pptx,xls,xlsx,odt,odp,ods,ott,otp,ots,rtf,htm,html,txt,log)
    -params "<key>=<value>[&<key>=<value>...]" (values must be URL-encoded; these pass through to Solr update request)
    -out yes|no (default: no; yes outputs Solr response to console)
    -format solr (sends application/json content as Solr commands to /update instead of /update/json/docs)


Examples:

-*- JSON file: bin/post -c wizbang events.json
-*- XML files: bin/post -c records article*.xml
-*- CSV file: bin/post -c signals LATEST-signals.csv
-*- Directory of files: bin/post -c myfiles ~/Documents
-*- Web crawl: bin/post -c gettingstarted http://lucene.apache.org/solr -recursive 1 -delay 1
-*- Standard input (stdin): echo '{commit: {}}' | bin/post -c my_collection -type application/json -out yes -d
-*- Data as string: bin/post -c signals -type text/csv -out yes -d $'id,value\n1,0.47'
\end{verbatim}
\end{block}


\begin{block}{Ask Question}
\begin{itemize}
\item url example:
\begin{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=video}
\begin{itemize}
\item host: localhost
\item port: 8983
\item app name: solr
\item request handler: select
\item query: q
\end{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=video\&fl=id,name,price}
\begin{itemize}
\item fl: 返回的字段
\end{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=name:black}
\begin{itemize}
\item q=name:black      name值为black的文档
\end{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=price:[0\%20TO\%20400]\&fl=id,name,price}
\begin{itemize}
\item price:[0\%20TO\%20400]    范围查询 链接部分需要 urlencode
\end{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=price:[0\%20TO\%20400]\&fl=id,name,price\&facet=true\&facet.field=cat}
\begin{itemize}
\item facet=true 相当于分组 (facet翻译：方面、侧面、宝石切面。意思是根据facet进行分类[分成几个侧面])
\item facet.field=cat
\item facet 的字段必须被索引
\item 可以根据分组进行再次查询
\begin{itemize}
\item \url{http://localhost:8983/solr/gettingstarted/select?q=price:0\%20TO\%20400\&fl=id,name,price\&facet=true\&facet.field=cat\&fq=cat:software}
\end{itemize}
\end{itemize}
\end{itemize}
\item documention
\begin{itemize}
\item responseHeader
\begin{verbatim}
<lst name="responseHeader">
<int name="status">0</int>
<int name="QTime">85</int>
<lst name="params">
<str name="q">video</str>
</lst>
</lst>
\end{verbatim}
\item result 包括一个或者多个doc标签
\begin{verbatim}
<result name="response" numFound="3" start="0">xml
<doc>xml
<str name="id">MA147LL/A</str>xml
<arr name="name">xml
<str>Apple 60 GB iPod with Video Playback Black</str>xml
</arr>xml
<arr name="manu">xml
...
\end{verbatim}
\item facet\_counts
\begin{verbatim}
<lst name="facet_counts">
  <lst name="facet_queries"/>
  <lst name="facet_fields">
  <lst name="cat">
  <int name="electronics">9</int>
  <int name="connector">2</int>
  <int name="hard drive">2</int>
  <int name="memory">2</int>
  <int name="search">2</int>
  <int name="software">2</int>
  <int name="camera">1</int>
  <int name="copier">1</int>
  <int name="electronics and stuff2">1</int>
  <int name="multifunction printer">1</int>
  <int name="music">1</int>
  <int name="printer">1</int>
  <int name="scanner">1</int>
  <int name="currency">0</int>
  <int name="electronics and computer1">0</int>
  <int name="graphics card">0</int>
  </lst>
  </lst>
  <lst name="facet_ranges"/>
  <lst name="facet_intervals"/>
  <lst name="facet_heatmaps"/>
  </lst>
\end{verbatim}
\end{itemize}
\end{itemize}
\end{block}
\end{frame}
\begin{frame}[label={sec:org5755c49}]{Using the Solr Administration User Interface}
\begin{block}{访问}
\url{http://hostname:port/solr}
\end{block}


\begin{block}{获取帮助}
底部链接
\begin{itemize}
\item 帮助文档
\item issue tracker
\item IRC 聊天室
\item 社区论坛
\item 查询语句的语法
\end{itemize}
\end{block}


\begin{block}{Logging}
\begin{itemize}
\item 黄色高亮的有记录日志的能力
\item 黑体字部分不受root影响
\end{itemize}
\end{block}


\begin{block}{Cloud}
\begin{block}{Tree}
显示zookeeper内部数据
\end{block}

\begin{block}{graph}
显示collection的分片信息
\end{block}

\begin{block}{Dump}
获取一份ZooKeeper中的solr数据快照。（帮助调试）
\end{block}
\end{block}


\begin{block}{Collections / Core Admin}
一个实例时叫CoreAdmin 多个实例Collection
\end{block}


\begin{block}{Thread Dump}
监视当前活动的线程，绿色对号是RUNNABLE
鼠标放到名字上会有状态显示:
\begin{center}
\begin{tabular}{ll}
name & desc\\
NEW & 未启动\\
RUNNABLE & 在jvm中运行\\
BLOCKED & 阻塞\\
WAITING & 等待\\
TIMED\_WAITING & 有时间的等待\\
TERMINATED & 退出\\
\end{tabular}
\end{center}
\end{block}


\begin{block}{Collection-Specific Tools(只有在cloud下才能看到)}
\begin{block}{Analysis}
分析查询语句
\end{block}

\begin{block}{Documents}
更新数据
\end{block}

\begin{block}{Files}
configuration files | solrCloud展示的是ZooKeeper中的配置文件
\begin{enumerate}
\item solrconfig.xml
\begin{itemize}
\item 定义了solr如何索引内容和响应请求
\end{itemize}
\item Schema 定义数据类型
\begin{itemize}
\item 文档字段
\end{itemize}
\end{enumerate}
\end{block}


\begin{block}{Stream}
raw版本的query界面
\end{block}


\begin{block}{Schema}
\begin{enumerate}
\item 选择字段
\item load term info 加载根据条件取出的前N个的信息(只从Collection的一个Core取数据作为样本)
\end{enumerate}
\end{block}
\end{block}


\begin{block}{Core-Specific Tools}
\begin{block}{Ping}
查看是否能访问
\begin{itemize}
\item \url{http://localhost:8983/solr/}<core-name>/admin/ping
\item \url{http://localhost:8983/solr/gettingstarted\_shard1\_replica1/admin/ping?\_=1481531966193\&ts=1481531966193\&wt=json}
\end{itemize}
\end{block}


\begin{block}{Segment}
当前核心的片段数据
\end{block}
\end{block}
\end{frame}
\begin{frame}[fragile,label={sec:orgc0e77e6}]{Documents, Fields, and Schema Design}
 \begin{block}{Overview}
\begin{block}{原理简介}
\begin{itemize}
\item feed in (indexing or updating)
\item ask questions (query)
\end{itemize}
\end{block}
\begin{block}{Field Analysis}
告诉solr如何处理字段，如需要忽略的字段与转换形式（a,the,an,Running=>run）
\end{block}
\begin{block}{Schema File}
告诉solr如何对输入的文档简历索引
\begin{itemize}
\item 默认为*managed-schema*文件
\item Cloud模式没有此文件，只能通过api或者cloud-ui看到
\item api方式修改只能修改*managed schema*指定的文件
\item solrCloud不通过api方式修改schema只能通过 upconfig 和 downconfg 让ZooKeeper管理配置文件
\end{itemize}
\end{block}
\end{block}


\begin{block}{Schema Detail}
server/
\begin{block}{Solr Field Types}
\begin{block}{Field Type Definitions and Properties（完善属性定义）}
\begin{enumerate}
\item 字段类型定义可以包含四种类型
\begin{itemize}
\item name 必须
\item class 必须
\item 如果字段类型是TextField，可以加上对field analysis
\item 字段类型的属性，取决于class
\end{itemize}
\item 类型定义
\begin{itemize}
\item 放在fieldType标签中
\item 可以用type标签分组
\end{itemize}
\item Field Type Properties
\begin{itemize}
\item <fieldType name="date" class="solr.TrieDateField" sortMissingLast="true" omitNorms="true"/>
\item 属性被分成三种
\begin{enumerate}
\item 针对field type的class的属性
\item 常规属性
\begin{itemize}
\item name
\item class
\item positionIncrementGap (对multivalue field 处理时，给两个field的词人为加上distance)
\item autoGeneratePhraseQueries
\item docValuesFormat (docValues的格式)
\item postingsFormat
\end{itemize}
\item 字段默认属性（替换继承的默认属性）
\begin{itemize}
\item indexed (是否建立索引)
\item stored (是否存储内容)
\item docValues ( 可以提升如排序,分面,高亮的性能)
\item sortMissingFirst/sortMissingLast
\item multiValued (多值)
\end{itemize}
\end{enumerate}
\end{itemize}
\item 例子:
\end{enumerate}
\begin{verbatim}
<fieldType name="ancestor_path" class="solr.TextField">
  <analyzer type="index">
    <tokenizer class="solr.KeywordTokenizerFactory"/>
  </analyzer>
  <analyzer type="query">
    <tokenizer class="solr.PathHierarchyTokenizerFactory" delimiter="/"/>
  </analyzer>
</fieldType>
\end{verbatim}
\end{block}

\begin{block}{Field Types Included with Solr}
\end{block}
\begin{block}{Working with Currencies and Exchange Rates}
\end{block}
\begin{block}{Working with Dates}
\end{block}
\begin{block}{Working with Enum Fields}
\end{block}
\begin{block}{Working with External Files and Processes}
\end{block}
\end{block}


\begin{block}{Defining Fields}
\begin{block}{example}
\begin{itemize}
\item <field name="price" type="float" default="0.0" indexed="true" stored="true"/>
\end{itemize}
\end{block}

\begin{block}{Field Properties}
\begin{itemize}
\item name (must)
\item type (must)
\item default (optional)
\end{itemize}
\end{block}

\begin{block}{Optional Field Type Override Properties}
会覆盖掉 fieldType 属性的属性
\end{block}
\end{block}


\begin{block}{Copying Fields}
\begin{itemize}
\item 为一个数据应用多种不同的字段类型
\item 需要搜索多个字段, 可以通过*copyField*组成一个字段，然后配置成默认搜索此字段。
\item 使用*copyField*会造成索引数据的增长
\item source和dest开头或者结尾可以有*表示匹配所有(表示通配符)
\end{itemize}
\begin{block}{主要字段}
\begin{itemize}
\item source 被复制的字段名称
\item dest 复制到的名称
\item maxChars 限制从source最多复制的字符 (想要控制index大小时有用)
\end{itemize}
\end{block}

\begin{block}{example}
\begin{verbatim}
<copyField source="cat" dest="text" maxChars="30000" />
<copyField source="*_t" dest="text" maxChars="25000" />
\end{verbatim}
如果text中有数据，那么cat中的内容将会添加到text中。

如果dest的source是多个值组成的，或者dest有多个source需要把dest字段设置成multivalued="true"
\begin{verbatim}
<schema name="eshequn.post.db_post.0" version="1.1" xmlns:xi="http://www.w3.org/2001/XInclude">  
  <fields>  
    <field name="title" type="text" indexed="true" stored="false" />  
    <field name="content" type="text" indexed="true" stored="false" />  
    <field name="tc" type="text" indexed="true" stored="false" multiValued="true"/>  
  </fields>  
  <copyField source="title" dest="tc" />  
  <copyField source="content" dest="tc" />  
<
/schema>
\end{verbatim}
\end{block}
\end{block}


\begin{block}{Dynamic Fields}
顾名思义，动态字段。
\begin{verbatim}
<dynamicField name="*_i" type="int" indexed="true" stored="true"/>
\end{verbatim}
\end{block}


\begin{block}{Other Elements}
\begin{block}{Unique Key}
指定文档的唯一标志(更新文档的时候有用)
\end{block}
\begin{block}{Default Search Field \& Query Operator}
\begin{itemize}
\item <defaultSearchField/> 已经被df参数取代
\item <solrQueryParserdefaultOperator="OR"/> 被q.op取代
\end{itemize}
\end{block}
\begin{block}{Similarity}
用来在搜索时获取文档的相关度(score)。自定义评分器。
\begin{itemize}
\item 每个文档只能有一个全局的Similarity
\item 默认行为BM25SimilarityFactory
\item 通过<similarity/> 标签可以覆盖默认行为
\item 可以通过两种形式实现
\item \url{http://static.oschina.net/uploads/space/2012/0327/191046\_bwnq\_100580.png}
\end{itemize}
\begin{verbatim}
<similarity class="solr.BM25SimilarityFactory"/>
<similarity class="solr.DFRSimilarityFactory">
    <str name="basicModel">P</str>
    <str name="afterEffect">L</str>
    <str name="normalization">H2</str>
    <float name="c">7</float>
</similarity>
\end{verbatim}
\end{block}
\end{block}


\begin{block}{Schema API}
提供一种通过http请求来读取和修改schema的方式
\begin{itemize}
\item schema修改之后只会改变后来的文档索引形式，不会改变之前的索引文档。所以必须重新索引所有的文档
\item output format： json | xml
\item \url{http://}<host>:<port>/solr/<collection\_name>/schema/
\end{itemize}
\begin{block}{API Entry Points}
\begin{itemize}
\item /schema: retrieve the schema, or modify the schema to add, remove, or replace fields, dynamic fields, copy fields, or field types
\item /schema/fields: retrieve information about all defined fields or a specific named field
\item /schema/dynamicfields: retrieve information about all dynamic field rules or a specific named dynamic rule
\item /schema/fieldtypes: retrieve information about all field types or a specific field type
\item /schema/copyfields: retrieve information about copy fields
\item /schema/name: retrieve the schema name
\item /schema/version: retrieve the schema version
\item /schema/uniquekey: retrieve the defined uniqueKey
\item /schema/similarity: retrieve the global similarity definition
\item /schema/solrqueryparser/defaultoperator: retrieve the default operator
\end{itemize}
\end{block}

\begin{block}{Modify the Schema}
\begin{verbatim}
    "add-field":{ "name":"sell-by", "type":"tdate", "stored":true } 
}' http://localhost:8983/solr/gettingstarted/schema
\end{verbatim}

\begin{block}{Schema Changes among Replicas}
在一个复制集上做的更改会改到其他的复制集上面
\end{block}
\end{block}

\begin{block}{Retrieve Schema Information}
\begin{verbatim}
curl http://localhost:8983/solr/gettingstarted/schema?wt=json
curl http://localhost:8983/solr/gettingstarted/schema?wt=xml
curl http://localhost:8983/solr/gettingstarted/schema?wt=schema.xml
curl http://localhost:8983/solr/gettingstarted/schema/fields?wt=json[fl=string,string
&includeDynamic=bool&showDefaults=bool]
\end{verbatim}
\end{block}
\end{block}


\begin{block}{Putting the Pieces Together}
\begin{block}{Choosing Appropriate Numeric Types}
\begin{enumerate}
\item 一般情况下 使用
\begin{itemize}
\item TrieIntField
\item TrieLongField
\item TrieFloatField
\item TrieDoubleFiel
\item precisionStep="0"
\end{itemize}
\item 数字经常被指定范围
\begin{itemize}
\item precisionStep="8"
\end{itemize}
\end{enumerate}
\end{block}


\begin{block}{Working With Text}
\begin{enumerate}
\item 通过使用一个txt field将所有字段汇总成一个搜索(用到了copyField)
\item 通过copyField将一个字段作为不同的用处
\end{enumerate}
\end{block}


\begin{block}{DocValues}
\begin{itemize}
\item 传统的index是一种倒排索引\footnote{正排索引是指由文档找词，倒排索引是指由词找文档} 并且是term-to-document的list,对于使用term来搜索时，这种方式很快
\item 但是若是使用facet、sort、hightlight这些特性，就会很慢
\item docvalues 是一种 面向列 的字段索引方式，并且使用了document-to-value的list
\item indexed 和 docValues 只能指定一个为true
\item 只能开启以下几个类型的docValues
\begin{enumerate}
\item StrField
\item UUIDField
\item Trie* numeric fields
\item date
\item EnumField
\end{enumerate}
\end{itemize}
\end{block}

\begin{block}{Using DocValues}
\end{block}

\begin{block}{Schemaless Mode}
\end{block}
\end{block}
\end{block}
\end{frame}
\begin{frame}[label={sec:orgb79ac70}]{Using Analyzers, Tokenizers, and Filters}
\begin{block}{}
\end{block}
\end{frame}
\begin{frame}[fragile,label={sec:org6131507}]{Indexing and Basic Data Operations}
 三种常用的方式可以向solr index中填充数据
\begin{itemize}
\item Solr Cell
\item xml file
\item Solr's Java Client API
\end{itemize}
填入的数据总是要包含多个字段，每个字段都有一个name和一个content
实验文件夹：example/exampledocs/

\begin{block}{Post Tool}
\begin{block}{bin/post}
\begin{verbatim}
bin/post -c gettingstarted example/films/films.json
bin/post -h
bin/post -c gettingstarted *.xml
bin/post -c gettingstarted -p 8984 *.xml
bin/post -c gettingstarted -d '<delete><id>42</id></delete>'
bin/post -c gettingstarted *.csv
bin/post -c gettingstarted -params "separator=%09" -type text/csv data.csv
bin/post -c gettingstarted *.json
bin/post -c gettingstarted a.pdf

bin/post -p port -host host -c collection_name json_file.json
# 自动检测文件夹中的文档类型，递归的进行索引数据
bin/post -c gettingstarted afolder/
bin/post -c gettingstarted -filetypes ppt,html afolder/
# 索引一个带有密码的pdf 密码为SolrRocks
bin/post -u solr:SolrRocks -c gettingstarted a.pdf
\end{verbatim}
\end{block}


\begin{block}{SimplePostTool}
java -jar example/exampledocs/post.jar -h
\end{block}
\end{block}


\begin{block}{Uploading Data with Index Handlers}
\begin{verbatim}
curl -X POST -H 'Content-Type: application/json' 'http://localhost:8983/solr/my_collection/update' --data-binary ' [ { "id": "1", "title": "Doc 1" }, { "id": "2", "title": "Doc 2" } ]'
# 指定文件
curl 'http://localhost:8983/solr/techproducts/update?commit=true' --data-binary @example/exampledocs/books.json -H 'Content-type:application/json'
\end{verbatim}
\end{block}


\begin{block}{Uploading Data with Solr Cell using Apache Tika}
导入多种不同的数据格式时有用，如二进制文件、word文档、pdf文档等。
\end{block}
\end{frame}

\begin{frame}[fragile,label={sec:org1ccf379}]{Search}
 \begin{block}{Overview}
\begin{block}{输入查询语句}
\end{block}
\begin{block}{查询语句被 \alert{request handler} 处理 (此插件定义了solr处理请求的逻辑)}
\end{block}
\begin{block}{调用 \alert{query parser} (解析器解释查询的条件和参数)}
\begin{enumerate}
\item 解析器的种类
\begin{enumerate}
\item Standard Query Parser (清晰)
\item DisMax (很少报错)
\item eDisMax (扩展版的DisMax，完全支持 lucene 查询语法)
\end{enumerate}
\item common query parameters  (支持全部的解析器)
\item 解析器输入种类
\begin{enumerate}
\item 查询语句
\item 对查询语句的微调参数
\item 对查询结果展示的控制
\end{enumerate}
\end{enumerate}
\end{block}
\begin{block}{*filter query*(fq) (filter query 会开辟一块单独的缓存，这种策略对性能提升很大)}
\begin{enumerate}
\item Filter queries 只查询索引中存在的数据
\end{enumerate}
\end{block}
\begin{block}{指定特定的条件高亮}
\end{block}
\begin{block}{返回结果可以有一个小片段，像是谷歌的搜索}
\end{block}
\begin{block}{对结果分组}
\begin{enumerate}
\item faceting
\begin{enumerate}
\item facet 分组字段（对结果进行分组）
\item facet count 分组得到的结果的数量
\item constraints 分组得到的结果的值
\item breadcrumb 面包屑（已经应用的facet）
\item list 结果详情
\end{enumerate}
\item clustering
\end{enumerate}
\end{block}
\begin{block}{MoreLikeThis}
\end{block}
\begin{block}{response writer (返回结果的形式)}
\begin{enumerate}
\item XML Response Writer
\item JSON Response Writer
\end{enumerate}
\end{block}
\end{block}


\begin{block}{通用查询语句}
\begin{block}{defType:}
\begin{enumerate}
\item 选择查询解析器
\item dismax/lucene
\item defType=dismax
\end{enumerate}
\end{block}

\begin{block}{sort:}
\begin{enumerate}
\item 对返回结果排序，asc|desc
\item 可以对数字和字母排序
\item 排序规则
\begin{enumerate}
\item 根据文档相关程度排序
\item 或者是根据字段的值排序，这个字段的值要么被索引要么使用了*DocValues*
\end{enumerate}
\item 单独字段排序：<field\_name>+(asc|desc)
\item 多字段排序：sort=<field name>+<direction>,<field name>+<direction>],\ldots{}
\end{enumerate}
\end{block}

\begin{block}{start:}
\begin{itemize}
\item 初始位置
\end{itemize}
\end{block}

\begin{block}{rows:}
\begin{itemize}
\item 相当于mysql中的limit
\end{itemize}
\end{block}

\begin{block}{fq:}
\begin{enumerate}
\item 对结果过滤的条件
\item 对将要返回的文档过滤（不会影响score【猜测是相关度】）
\item 对复杂的query进行加速，因为会对fq进行的查询独立进行缓存
\item fq参数可以出现多次
\begin{enumerate}
\item `fq=popularity:[10 TO *]\&fq=section:0` （当条件经常单独出现时）
\item `fq=+popularity:[10 TO *] +section:0` (当条件经常单独出现时)
\end{enumerate}
\item url-encoding 参考地址 ：  \url{http://meyerweb.com/eric/tools/dencoder/}
\end{enumerate}
\end{block}

\begin{block}{fl:}
\begin{enumerate}
\item 设定返回结果的字段,用逗号或者空格分开
\item stored="true" or docValues="true" or useDocValuesAsStored="true"(在docvalues模式开启时是默认的)
\item 字段可以是个函数 如：fl=id,title,product(price,popularity)
\item 别名：fl=id,sales\_price:price,secret\_sauce:prod(price,popularity),why\_score:[explain style=nl]
\end{enumerate}
\end{block}

\begin{block}{debug:}
\begin{enumerate}
\item 返回额外的调试信息。
\item debug=timing只返回时间信息.
\item debug=results返回对返回结果的每个文档的解释。
\item debug=all(true)将返回所有的调试信息。debugQuery=true
\end{enumerate}
\end{block}

\begin{block}{explainOther:}
\begin{itemize}
\item q=supervillians\&debugQuery=on\&explainOther=id$\backslash$:juggernaut
\item 返回调试信息
\item 必须加上debugQuery=on否则不返回debug字段
\end{itemize}
\end{block}

\begin{block}{timeAllowed：}
\begin{itemize}
\item 超过此时间之后，只会返回一部分数据
\end{itemize}
\end{block}

\begin{block}{omitHeader:}
\begin{itemize}
\item 不返回头部信息
\end{itemize}
\end{block}

\begin{block}{wt:}
\begin{itemize}
\item 返回结果的格式
\end{itemize}
\end{block}

\begin{block}{cache=false:}
\begin{itemize}
\item 停止缓存所有的查询和过滤条件的结果
\end{itemize}
\end{block}

\begin{block}{logParamsList(version >= 4.7):}
\begin{itemize}
\item 默认会记录所有的字段，logParamsList=param1,param2逗号分割的参数
\end{itemize}
\end{block}

\begin{block}{echoParams:}
在response header 中的 params 字段中显示所用到的查询字段
\begin{enumerate}
\item explicit(默认)
\item all
\item none
\end{enumerate}
\end{block}
\end{block}


\begin{block}{The Standard Query Parser (lucene parser)}
优点：直观，缺点：不能有语法错误
\begin{block}{q}
查询语句，强制性
\begin{verbatim}
http://localhost:8983/solr/techproducts/select?q=id:SP2514N
q=*:* 查询全部,特殊情况
\end{verbatim}
\begin{center}
\begin{tabular}{ll}
? & 匹配单个字符\\
* & 匹配多个字符\\
\textasciitilde{} & 模糊搜索 roam\textasciitilde{} 将会匹配foam，foams等\\
\textasciitilde{}1 & 模糊搜索 roam\textasciitilde{} 将会匹配foam，不会匹配foams，因为foams改动了两个字\\
"jakarta apache"\textasciitilde{}10 & 两个词之间改动10个位置可以匹配到\\
mod\_date:[20020101 TO 20030101] & 范围查询\\
title:\{Aida TO Smith\} & 大括号表示不包含上下边界\\
jakarta\^{}4 apache & boost factor 可以通过改变这个值改变查询时的相关度,可以小于1\\
(description:blue OR color:blue)\^{}=1.0 text:shoes & 将匹配括号中的语句的文档相关度设置成1\\
title:"The Right Way" AND text:go & 指定字段查询\\
title:"Do it right" AND go & 第二个字段直接查询默认搜索字段\\
(AND/\&\&),(OR/ll),(+),(-),(NOT !) & 操作符\\
+ - \&\& ll ! ( ) \{ \} [ ] \^{} " \textasciitilde{} * ? : / & 需要转义的字符\\
(jakarta OR apache) AND website & 表达式 website存在并且有jakarta或者apache\\
\end{tabular}
\end{center}
\end{block}


\begin{block}{q.op}
指定查询语句默认是用*AND*还是*OR*
\end{block}


\begin{block}{df}
指定默认搜索的字段
\end{block}
\end{block}


\begin{block}{The DisMax Query Parser}
\begin{block}{Parameters}
\end{block}
\end{block}


\begin{block}{Faceting}
对结果进行分类(分组),很方便查询每个条件有多少文档。
必要条件：facet的字段必须被索引indexed=true
\begin{block}{General Parameters}
\begin{enumerate}
\item facet=true(on) ,  默认为假
\begin{enumerate}
\item 不会改变结果字段，只会添加一个 facet\_counts 字段
\end{enumerate}
\item facet.query 指定计算count的表达式
facet.query=\{!myfunc\}name\textasciitilde{}fred
\end{enumerate}
\end{block}

\begin{block}{Field-Value Faceting Parameters}
\begin{enumerate}
\item facet.field  
分组的字段
\item facet.prefix 
限制facet.field 的前缀，不同则不分类
\item facet.limit  
facet\_counts 字段返回条数, 默认100
\item facet.sort
\begin{itemize}
\item count 根据数量排序
\item index (default)
\end{itemize}
\item facet.offset 
开始条数,偏移量,它与facet.limit配合使用可以达到分页的效果
\item facet.mincount 
facet\_counts 字段中最小的数量，低于此值不显示
\item facet.missing 
是否返回没有值的field
\item facet.method 
取值为enum或fc,默认为fc, fc表示Field Cache
\begin{itemize}
\item enum 适用于值较少的
\end{itemize}
\end{enumerate}
\end{block}


\begin{block}{facet.pivot}
不会翻译， 作用比较像是 mysql 中将两个字段进行分组,然后rollup,获得一个统计数据
返回字段 facet\_count.facet\_pivot
\begin{itemize}
\item \url{http://localhost:8983/solr/techproducts/select?q=*:*\&facet.pivot=cat,popularity,inStock\&facet.pivot=popularity,cat\&facet=true\&facet.field=cat\&facet.limit=5\&rows=0\&wt=json\&indent=true\&facet.pivot.mincount=2}
\end{itemize}
\end{block}
\end{block}



\begin{block}{Highlighter}
\begin{block}{Standard Highlighter}
\end{block}
\end{block}
\end{frame}

\begin{frame}[fragile,label={sec:org80f600b}]{solrCloud}
 server/solr
\begin{block}{features}
\begin{enumerate}
\item 集中式配置管理
\item 自动化负载均衡和故障切换
\item ZooKeeper 整合
\end{enumerate}
\end{block}


\begin{block}{相关概念}
\begin{block}{Node}
solr实例
\end{block}
\begin{block}{Cluster}
可以包含多个Collection，由一个或者多个node组成
\end{block}
\begin{block}{Collection}
在SolrCloud集群中逻辑意义上的完整的索引, 可以分到多个Shards上
\end{block}
\begin{block}{Config Set}
Solr Core提供服务必须的一组配置文件
\end{block}
\begin{block}{Leader}
赢得选举的Shard replicas
\end{block}
\begin{block}{Replica}
Shard的一个拷贝
\end{block}
\begin{block}{Shard}
Collection的逻辑分片。一个shard上面一个leader replica
\end{block}
\begin{block}{Zookeeper}
Zookeeper提供分布式锁功能，对SolrCloud是必须的。它处理Leader选举。Solr可以以内嵌的Zookeeper运行，但是建议用独立的，并且最好有3个以上的主机。 
\end{block}
\end{block}


\begin{block}{配置外部 ZooKeeper}
\alert{需要多少Zookeeper} 想要挂掉F个机器时还能正常提供服务，就需要 2*F+1 台机器
下载地址： \url{http://zookeeper.apache.org/releases.html}
\begin{block}{一个实例}
\begin{itemize}
\item <ZOOKEEPER\_HOME>/conf/zoo.cfg
\end{itemize}
\begin{verbatim}
# 一个滴答（时间单位， 毫秒）
tickTime=2000 
# 数据文件夹
dataDir=/var/lib/zookeeper
# 端口号
clientPort=2181
\end{verbatim}
\end{block}


\begin{block}{集群}
\begin{block}{配置文件}
\begin{itemize}
\item zoo.cfg
\begin{verbatim}
dataDir=/var/lib/zookeeperdata/1
clientPort=2181
# 初始化连接最大忍受的滴答次数
initLimit=5
# leader 与 follower 发送消息最大的等待时间
syncLimit=2
# server.{第几号服务器}={ip地址}:{服务器与leader交换信息的端口}:{leader服务器挂掉之后，选举信息通信的端口}
server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890
\end{verbatim}

\item zoo2.cfg
\begin{verbatim}
tickTime=2000
dataDir=~/self/zoo/zoodata/2
clientPort=2182
initLimit=5
syncLimit=2
server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890
\end{verbatim}

\item zoo3.cfg
\begin{verbatim}
tickTime=2000
dataDir=~/self/zoo/zoodata/3
clientPort=2183
initLimit=5
syncLimit=2
server.1=localhost:2888:3888
server.2=localhost:2889:3889
server.3=localhost:2890:3890
\end{verbatim}

\item myid file
\begin{verbatim}
mkdir -p zoodata/{1,2,3}
echo 1 > 1/myid
echo 2 > 2/myid
echo 3 > 3/myid
\end{verbatim}

\item 启动三个zookeeper
\end{itemize}
cd <ZOOKEEPER\_HOME>
bin/zkServer.sh start zoo.cfg
bin/zkServer.sh start zoo2.cfg
bin/zkServer.sh start zoo3.cfg
\begin{itemize}
\item 引用外部zookeeper
\end{itemize}
bin/solr start -e cloud -z localhost:2181,localhost:2182,localhost:2183 -noprompt
\begin{verbatim}
➜  zoo bin/zkServer.sh status zoo.cfg
ZooKeeper JMX enabled by default
Using config: /Users/wudanyang/self/zoo/bin/../conf/zoo.cfg
Mode: follower
➜  zoo bin/zkServer.sh status zoo2.cfg
ZooKeeper JMX enabled by default
Using config: /Users/wudanyang/self/zoo/bin/../conf/zoo2.cfg
Mode: leader
➜  zoo bin/zkServer.sh status zoo3.cfg
ZooKeeper JMX enabled by default
Using config: /Users/wudanyang/self/zoo/bin/../conf/zoo3.cfg
Mode: follower
\end{verbatim}
\end{block}
\end{block}



\begin{block}{通过zookeeper管理配置文件}
上传配置文件
sh zkcli.sh -cmd upconfig -zkhost <host:port> -confname <name for configset> -solrhome <solrhome> -confdir <path to directory with configset>
cd \emph{Users/wudanyang/self/solr/server/scripts/cloud-scripts
sh zkcli.sh -cmd upconfig -zkhost localhost:2181 -confname yang -confdir ..}../../server/solr/configsets/basic\_configs/conf
\end{block}


\begin{block}{添加 node}
\begin{itemize}
\item zkServer.sh start *.cfg
\item bin/solr start -cloud -s <conf path> -p 8987 -z localhost:2181 \# 添加一个节点,配置文件夹中必须包含一个solr.xml文件
\item bin/solr start -cloud -s confs/cloud/conf/ -p 8984 -z localhost:2181,localhost:2182,localhost:2183
\item zkServer.sh stop
\end{itemize}
\end{block}


\begin{block}{Collections API}
创建多个shard需要多个node
nodeNum = shardNum * replicationFactorNum
\begin{itemize}
\item \url{http://localhost:8983/solr/admin/collections?action=CREATE\&name=yang\&numShards=1\&replicationFactor=3\&collection.configName=yang}
\item \url{http://localhost:8983/solr/admin/collections?action=RELOAD\&name=yang\_test2}
\end{itemize}
\end{block}
\end{block}


\begin{block}{Run Examples}
\begin{block}{通过 bin/solr restart 可以重启节点}
bin/solr restart -c -p 8983 -s example/cloud/node1/solr
-c 启动solrcloud模式
-p 指定端口
-h 指定host
bin/solr restart -c -p 7574 -z localhost:9983 -s example/cloud/node2/solr
-z zookeeper服务器地址
\end{block}
\begin{block}{向集群中添加一个节点}
mkdir <solr.home for new solr node>
cp <existing solr.xml path> <new solr.home>
bin/solr start -cloud -s solr.home/solr -p <port num> -z <zk hosts string>
bin/solr start -cloud -s <conf path> -p 8987 -z localhost:2181 \# 添加一个节点,配置文件夹中必须包含一个solr.xml文件

也可以通过以下命令,将solr.xml上传到zookeeper，这样就不用总是复制solr.xml到新的节点
zkcli.sh -zkhost localhost:2181 -cmd putfile /solr.xml /path/to/solr.xml

\begin{block}{example}
mkdir -p example/cloud/node3/solr
cp server/solr/solr.xml example/cloud/node3/solr
第一次以cloud模式启动时会启动一个zookeeper服务器端口号是cloud端口号加上1000
bin/solr start -cloud -s example/cloud/node3/solr -p 8987 -z localhost:9983
\end{block}
\end{block}
\end{block}
\end{frame}
\begin{frame}[label={sec:org7c8b5bf}]{Issues}
\begin{block}{学习时遇到的问题}
\begin{block}{Q: ZooKeeper JMX enabled by default Using config: \emph{Users/wudanyang/self/zoo/bin}../conf/zoo.cfg Error contacting service. It is probably not running.}
A: bin/zkServer.sh start-foreground 可以查看到
\end{block}

\begin{block}{Q: ZooKeeper 执行 bin/zkServer.sh status 说未启动}
A: ps aux | grep zookeeper
查看是否存在
\end{block}

\begin{block}{Q: SolrCore Initialization Failures}
A: 未上传配置
sh zkcli.sh -cmd upconfig -zkhost localhost:2181 -confname gettingstarted -confdir ../../../server/solr/configsets/basic\_configs/conf
\end{block}


\begin{block}{Q: 通过api创建collection时, 返回localhost未返回任何数据}
A: 请求地址应该是solr服务器，而不是zookeeper服务器。
localhost:8983/solr/admin/collectinos?action=CREATE\&name=yang\&numShards=1\&replicationFactor=3\&collection.configName=yang
\end{block}


\begin{block}{Q: Cannot create collection tinycollection. Value of maxShardsPerNode is 1, and the number of live nodes is 4. This allows a maximum of 4 to be created. Value of numShards is 2 and value of replicationFactor is 3. This requires 6 shards to be created (higher than the allowed number)</str>}
A:将replicationFactor降低
\url{http://localhost:8983/solr/admin/collections?action=CREATE\&name=yang\&collection.configName=yang\&numShards=1\&replicationFactor=1\&wt=json}
\end{block}


\begin{block}{Q: 在zookeeper中找不到配置文件}
A: 配置文件疑似在上传到zookeeper时放到了名为zoo\_data/version-\{num\}/log.number的二进制文件中
\end{block}


\begin{block}{Q: 为何在6.*以上的solr中store=false 仍然能看到字段被返回了}
A: 在6.*之后，string 的 docValues=true 为默认值
\end{block}


\begin{block}{Q: int类型为何docValues=false与stored=false还能在结果中看到字段}
A: 未知
\end{block}


\begin{block}{Q: 从 example/example-DIH/solr/ 中复制solr.xml 作为cloud的配置文件无法生效}
A: 因为默认的配置文件里面有 standalone="yes" 及不使用集群方式
\end{block}

\begin{block}{Q: 为什么找不到 Can't find resource 'schema.xml'}
A: example 文件夹中的配置文件为 managed-schema 需要改成 schema.xml 上传才行
\end{block}
\end{block}


\begin{block}{公司系统发现的问题}
\begin{enumerate}
\item 脚本文件处于无版本控制状态
创建git本地库，后续可以跟运维商量加上一个solr脚本的git库
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}[label={sec:orge918d9b}]{Cache}
缓存在 Solr 中充当了一个非常重要的角色，Solr 中主要有这三种缓存：
\begin{enumerate}
\item Filter cache（过滤器缓存），用于保存过滤器（fq 参数）和层面搜索的结果
\item Document cache（文档缓存），用于保存 lucene 文档存储的字段
\item Query result（查询缓存），用于保存查询的结果
\item 还有第四种缓存，lucene 内部的缓存，不过该缓存外部无法控制到。
\end{enumerate}

通过这 3 种缓存，可以对 solr 的搜索实例进行调优。调整这些缓存，需要根据索引库中文档的数量，每次查询结果的条数等。
在调整参数前，需要事先得到 solr 示例中的以下信息： 索引中文档的数量 每秒钟搜索的次数 过滤器的数量 一次查询返回最大的文档数量
不同查询和不同排序的个数，这些数量可以在 solr admin 页面的日志模块找到。

假设以上的值分别为：
索引中文档的数量：1000000
每秒钟搜索的次数：100
过滤器的数量：200
一次查询返回最大的文档数量：100
不同查询和不同排序的个数：500
然后可以开始修改 solrconfig.xml 中缓存的配置了，



第一个是过滤器缓存：
第二个是查询结果缓存：
第三个是文档缓存：
这几个配置是基于以上的几个假设的值进行调优的。
\end{frame}
\end{document}
